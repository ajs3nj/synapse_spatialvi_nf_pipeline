# spatialvi_nf_pipeline (Orca Orchestration)

A **meta-workflow** for running [spatialvi](https://github.com/sagebio-ada/spatialvi) with data from Synapse and indexing results back to Synapse, orchestrated via [Orca](https://github.com/Sage-Bionetworks-Workflows/py-orca).

## Overview

This workflow uses existing [nf-synapse](https://github.com/Sage-Bionetworks-Workflows/nf-synapse) workflows (SYNSTAGE and SYNINDEX) for Synapse interaction and adds a tarball step for spatialvi:

```
┌─────────────────────┐     ┌─────────────────┐     ┌─────────────────┐     ┌─────────────────────┐
│ 1. nf-synapse       │ ──▶ │ 2. make_tarball │ ──▶ │ 3. spatialvi    │ ──▶ │ 4. nf-synapse       │
│    SYNSTAGE         │     │ (this pipeline) │     │                 │     │    SYNINDEX         │
└─────────────────────┘     └─────────────────┘     └─────────────────┘     └─────────────────────┘
   Download from              Create FASTQ            Run spatialvi         Index results
   Synapse to S3              tarballs +              analysis              back to Synapse
                              samplesheet
```

---

## Parameters

### For this pipeline (make_tarball step)

| Parameter | Description | Required |
|-----------|-------------|----------|
| `--entry` | Workflow entry point: `make_tarball` | Yes |
| `--input` | Path to synstage output samplesheet (with S3 paths) | Yes |
| `--outdir` | S3 URI for outputs | Yes |
| `--cytassist` | Use `cytaimage` column instead of `image` | No (default: false) |

---

## Samplesheet Formats

### Step 1: SYNSTAGE Input

Create a CSV with `syn://` URIs for Synapse files. SYNSTAGE will replace these with S3 paths.

| Column | Description |
|--------|-------------|
| `sample` | Unique sample ID |
| `fastq_1` | Synapse URI for FASTQ file 1 (e.g., `syn://syn64002035`) |
| `fastq_2` | Synapse URI for FASTQ file 2 |
| `fastq_3` | Synapse URI for FASTQ file 3 |
| `fastq_4` | Synapse URI for FASTQ file 4 |
| `image` | Synapse URI for microscopy image |
| `slide` | Visium slide ID (e.g., `V11J26`) |
| `area` | Slide area (e.g., `B1`), can be empty |

Example (`examples/1_synstage_input.csv`):
```csv
sample,fastq_1,fastq_2,fastq_3,fastq_4,image,slide,area
ANNUBP_V42N08_047_A1,syn://syn64002035,syn://syn64002036,syn://syn64002037,syn://syn64002038,syn://syn64002032,V42N08-047,A1
```

### Step 2: SYNSTAGE Output / make_tarball Input

After SYNSTAGE runs, `syn://` URIs are replaced with S3 paths:

```csv
sample,fastq_1,fastq_2,fastq_3,fastq_4,image,slide,area
ANNUBP_V42N08_047_A1,s3://bucket/synstage/syn64002035/file.fastq.gz,...,V42N08-047,A1
```

### Step 3: spatialvi Input (generated by make_tarball)

The `make_tarball` step creates tarballs and outputs `spatialvi_samplesheet.csv`:

```csv
sample,fastq_dir,image,slide,area
ANNUBP_V42N08_047_A1,s3://bucket/tarballs/ANNUBP_V42N08_047_A1/ANNUBP_V42N08_047_A1_fastqs.tar.gz,s3://bucket/tarballs/ANNUBP_V42N08_047_A1/image_out/image.tif,V42N08-047,A1
```

---

## Outputs

### After Step 1 (SYNSTAGE)
```
s3://bucket/project/synstage/
├── syn64002035/
│   └── file1.fastq.gz
├── syn64002036/
│   └── file2.fastq.gz
└── synstage_input.csv    ← Updated with S3 paths
```

### After Step 2 (make_tarball)
```
s3://bucket/project/
├── tarballs/
│   └── SAMPLE1/
│       ├── SAMPLE1_fastqs.tar.gz
│       └── image_out/
│           └── image.tif
└── spatialvi_samplesheet.csv    ← Use this for Step 3
```

### After Step 3 (spatialvi)
```
s3://bucket/project/spatialvi_results/
├── SAMPLE1/
│   └── ...
└── multiqc/
    └── ...
```

### After Step 4 (SYNINDEX)
Results from `spatialvi_results/` are indexed into your Synapse folder.

---

## Notes

- SYNSTAGE replaces `syn://` URIs with S3 paths in-place in the samplesheet
- The `slide` and `area` columns pass through all steps unchanged
- spatialvi identifies reads by filename convention (`_R1_`, `_R2_`, `_I1_`, `_I2_`)
- Requires `SYNAPSE_AUTH_TOKEN` secret configured in Tower workspace

---

## Running with Orca (Recommended)

Orca orchestrates all four steps automatically.

### Prerequisites
```bash
pip install py-orca
```

### Configure your dataset

Edit `orca/spatialvi_workflow.py` and modify `generate_datasets()`:

```python
def generate_datasets() -> list[SpatialviDataset]:
    return [
        SpatialviDataset(
            id="my_dataset",
            synstage_input_samplesheet="s3://bucket/project/synstage_input.csv",
            synapse_output_folder="syn123456",
            bucket_name="my-bucket",
            project_prefix="spatialvi_project",
            spaceranger_reference="s3://bucket/refdata-gex-GRCh38-2020-A.tar.gz",
            spaceranger_probeset="s3://bucket/probeset.csv",  # optional
        )
    ]
```

### Run
```bash
cd orca/
python spatialvi_workflow.py
```

The script will:
1. Launch SYNSTAGE and wait for completion
2. Launch make_tarball and wait for completion
3. Launch spatialvi and wait for completion
4. Launch SYNINDEX and wait for completion

---

## Running Manually on Tower

If you prefer to run each step manually:

### Step 1: SYNSTAGE
1. Pipeline: `Sage-Bionetworks-Workflows/nf-synapse`
2. Parameters:
   - `entry`: `synstage`
   - `input`: `s3://bucket/project/synstage_input.csv`
   - `outdir`: `s3://bucket/project/synstage`
3. Secrets: `SYNAPSE_AUTH_TOKEN`

### Step 2: make_tarball
1. Pipeline: `ajs3nj/synapse_spatialvi_nf_pipeline` (branch: `orca-orchestration`)
2. Parameters:
   - `entry`: `make_tarball`
   - `input`: `s3://bucket/project/synstage/synstage_input.csv`
   - `outdir`: `s3://bucket/project`

### Step 3: spatialvi
1. Pipeline: `sagebio-ada/spatialvi`
2. Parameters:
   - `input`: `s3://bucket/project/spatialvi_samplesheet.csv`
   - `outdir`: `s3://bucket/project/spatialvi_results`
   - `spaceranger_reference`: your reference
   - `spaceranger_probeset`: your probeset (if needed)

### Step 4: SYNINDEX
1. Pipeline: `Sage-Bionetworks-Workflows/nf-synapse`
2. Parameters:
   - `entry`: `synindex`
   - `s3_prefix`: `s3://bucket/project/spatialvi_results`
   - `parent_id`: `syn123456`
3. Secrets: `SYNAPSE_AUTH_TOKEN`

---

## Running Locally

```bash
# Step 1: SYNSTAGE
nextflow run Sage-Bionetworks-Workflows/nf-synapse \
  --entry synstage \
  --input s3://bucket/project/synstage_input.csv \
  --outdir s3://bucket/project/synstage \
  -profile docker

# Step 2: make_tarball
nextflow run . --entry make_tarball \
  --input s3://bucket/project/synstage/synstage_input.csv \
  --outdir s3://bucket/project \
  -profile docker

# Step 3: spatialvi
nextflow run sagebio-ada/spatialvi \
  --input s3://bucket/project/spatialvi_samplesheet.csv \
  --outdir s3://bucket/project/spatialvi_results \
  --spaceranger_reference <ref> \
  --spaceranger_probeset <probeset>

# Step 4: SYNINDEX
nextflow run Sage-Bionetworks-Workflows/nf-synapse \
  --entry synindex \
  --s3_prefix s3://bucket/project/spatialvi_results \
  --parent_id syn123456 \
  -profile docker
```
